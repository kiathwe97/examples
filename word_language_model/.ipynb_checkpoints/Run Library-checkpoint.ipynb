{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (776.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.7 MB 1.9 kB/s eta 0:00:01    |█                               | 24.0 MB 6.9 MB/s eta 0:01:50     |██▌                             | 59.6 MB 5.6 MB/s eta 0:02:08     |██▉                             | 68.6 MB 9.8 MB/s eta 0:01:13     |███▋                            | 88.5 MB 2.7 MB/s eta 0:04:17     |████▋                           | 112.7 MB 3.3 MB/s eta 0:03:23     |██████▊                         | 163.1 MB 3.0 MB/s eta 0:03:25     |████████▋                       | 208.2 MB 3.5 MB/s eta 0:02:44     |█████████▉                      | 239.6 MB 3.7 MB/s eta 0:02:27     |██████████                      | 242.9 MB 3.7 MB/s eta 0:02:25     |██████████                      | 244.0 MB 3.7 MB/s eta 0:02:25     |█████████████                   | 317.8 MB 3.2 MB/s eta 0:02:23     |█████████████▍                  | 323.8 MB 3.1 MB/s eta 0:02:26     |███████████████▍                | 373.5 MB 3.5 MB/s eta 0:01:56     |███████████████▊                | 382.3 MB 971 kB/s eta 0:06:46     |█████████████████               | 414.8 MB 6.0 MB/s eta 0:01:01     |█████████████████▎              | 420.4 MB 6.0 MB/s eta 0:01:00     |█████████████████▌              | 424.0 MB 6.3 MB/s eta 0:00:56     |███████████████████▎            | 467.5 MB 3.2 MB/s eta 0:01:36     |███████████████████▍            | 470.7 MB 2.9 MB/s eta 0:01:45     |███████████████████▌            | 472.3 MB 2.9 MB/s eta 0:01:45     |█████████████████████▎          | 515.2 MB 3.2 MB/s eta 0:01:21     |██████████████████████▏         | 538.2 MB 3.1 MB/s eta 0:01:17     |███████████████████████▎        | 564.6 MB 3.7 MB/s eta 0:00:58     |███████████████████████▊        | 576.4 MB 3.4 MB/s eta 0:00:59     |███████████████████████▉        | 579.5 MB 3.4 MB/s eta 0:00:58     |█████████████████████████▎      | 613.7 MB 3.5 MB/s eta 0:00:47     |██████████████████████████▍     | 641.0 MB 2.5 MB/s eta 0:00:54     |██████████████████████████▋     | 646.2 MB 3.3 MB/s eta 0:00:41     |███████████████████████████▌    | 667.9 MB 2.8 MB/s eta 0:00:39     |████████████████████████████▉   | 699.7 MB 3.4 MB/s eta 0:00:23     |█████████████████████████████   | 703.8 MB 2.9 MB/s eta 0:00:26     |█████████████████████████████▌  | 716.5 MB 3.5 MB/s eta 0:00:18     |█████████████████████████████▉  | 725.3 MB 4.0 MB/s eta 0:00:13     |██████████████████████████████  | 726.9 MB 3.8 MB/s eta 0:00:14     |███████████████████████████████▏| 756.6 MB 2.6 MB/s eta 0:00:08\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=493275 sha256=e4e803199660fcb06695f69ccbc17dbf40a1997c8213cc5c8201f27bcfb3647c\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "Successfully built future\n",
      "Installing collected packages: future, dataclasses, torch\n",
      "Successfully installed dataclasses-0.8 future-0.18.2 torch-1.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 21 12:34:03 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 2080    Off  | 00000000:08:00.0  On |                  N/A |\n",
      "| 22%   47C    P8    28W / 215W |    751MiB /  7949MiB |     36%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.6.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 708.0 MB 34 kB/s s eta 0:00:01    |█                               | 23.2 MB 12.2 MB/s eta 0:00:57     |██▌                             | 55.2 MB 12.3 MB/s eta 0:00:53     |████▎                           | 94.1 MB 10.6 MB/s eta 0:00:58     |████▊                           | 103.8 MB 11.9 MB/s eta 0:00:51     |█████                           | 109.0 MB 10.6 MB/s eta 0:00:57     |█████████▎                      | 204.1 MB 10.7 MB/s eta 0:00:48     |██████████▋                     | 234.1 MB 12.1 MB/s eta 0:00:40     |██████████▊                     | 237.3 MB 12.1 MB/s eta 0:00:39     |████████████                    | 268.0 MB 12.1 MB/s eta 0:00:37     |███████████████▍                | 340.2 MB 2.1 MB/s eta 0:02:58     |███████████████▌                | 342.0 MB 2.1 MB/s eta 0:02:57     |███████████████▊                | 347.3 MB 10.6 MB/s eta 0:00:35     |███████████████▉                | 350.8 MB 10.6 MB/s eta 0:00:34     |████████████████                | 352.6 MB 10.6 MB/s eta 0:00:34     |████████████████▌               | 364.4 MB 12.3 MB/s eta 0:00:28     |██████████████████              | 397.0 MB 10.6 MB/s eta 0:00:30     |████████████████████            | 442.1 MB 12.1 MB/s eta 0:00:22     |██████████████████████          | 484.9 MB 12.3 MB/s eta 0:00:19     |██████████████████████          | 488.5 MB 12.3 MB/s eta 0:00:18     |███████████████████████▉        | 526.8 MB 10.6 MB/s eta 0:00:18     |█████████████████████████▉      | 570.6 MB 12.3 MB/s eta 0:00:12     |██████████████████████████▍     | 583.0 MB 10.5 MB/s eta 0:00:12     |██████████████████████████▉     | 594.2 MB 12.2 MB/s eta 0:00:10     |███████████████████████████▌    | 608.9 MB 10.6 MB/s eta 0:00:10     |█████████████████████████████   | 640.2 MB 12.2 MB/s eta 0:00:06     |█████████████████████████████   | 640.8 MB 12.2 MB/s eta 0:00:06     |█████████████████████████████▍  | 651.4 MB 12.1 MB/s eta 0:00:05     |██████████████████████████████  | 664.9 MB 10.6 MB/s eta 0:00:05     |███████████████████████████████▉| 703.2 MB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.18.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.2.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.0\n",
      "    Uninstalling torch-1.7.0:\n",
      "      Successfully uninstalled torch-1.7.0\n",
      "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./data.py --cuda --data ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"./main.py\", line 70, in <module>\r\n",
      "    corpus = data.Corpus(args.data)\r\n",
      "  File \"/tf/notebooks/NLP-Assignment2/word_language_model/data.py\", line 23, in __init__\r\n",
      "    self.train = self.tokenize(os.path.join(path, 'train.txt'))\r\n",
      "  File \"/tf/notebooks/NLP-Assignment2/word_language_model/data.py\", line 29, in tokenize\r\n",
      "    assert os.path.exists(path)\r\n",
      "AssertionError\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./main.py --cuda --data ./d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
